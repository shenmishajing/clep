__import__:
    task: &task multiclass
    num_classes: &num_classes 4
    labels: &labels [L, R, V, A]

model:
    init_args:
        evaluator_cfg:
            class_path: torchmetrics.MetricCollection
            init_args:
                metrics:
                    acc:
                        class_path: torchmetrics.Accuracy
                        init_args:
                            task: *task
                            num_classes: *num_classes
                            average: micro
                    F1:
                        class_path: torchmetrics.F1Score
                        init_args:
                            task: *task
                            num_classes: *num_classes
                            average: macro
                    PR-AUC:
                        class_path: torchmetrics.AveragePrecision
                        init_args:
                            task: *task
                            num_classes: *num_classes
                            average: macro
                    ROC-AUC:
                        class_path: torchmetrics.AUROC
                        init_args:
                            task: *task
                            num_classes: *num_classes
                            average: macro
                    acc_classwise:
                        class_path: torchmetrics.ClasswiseWrapper
                        init_args:
                            prefix: acc_
                            labels: *labels
                            metric:
                                class_path: torchmetrics.Accuracy
                                init_args:
                                    task: *task
                                    num_classes: *num_classes
                                    average: null
                    F1_classwise:
                        class_path: torchmetrics.ClasswiseWrapper
                        init_args:
                            prefix: F1_
                            labels: *labels
                            metric:
                                class_path: torchmetrics.F1Score
                                init_args:
                                    task: *task
                                    num_classes: *num_classes
                                    average: null
                    PR-AUC_classwise:
                        class_path: torchmetrics.ClasswiseWrapper
                        init_args:
                            prefix: PR-AUC_
                            labels: *labels
                            metric:
                                class_path: torchmetrics.AveragePrecision
                                init_args:
                                    task: *task
                                    num_classes: *num_classes
                                    average: null
                    ROC-AUC_classwise:
                        class_path: torchmetrics.ClasswiseWrapper
                        init_args:
                            prefix: ROC-AUC_
                            labels: *labels
                            metric:
                                class_path: torchmetrics.AUROC
                                init_args:
                                    task: *task
                                    num_classes: *num_classes
                                    average: null

trainer:
    callbacks:
        change_item:
            - - 0
              - init_args:
                    monitor: val/F1
                    filename: "epoch:{epoch}-val_f1:{val/F1:.4g}.ckpt"
                    mode: max
